{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin-left: 0;\">\n",
    "    <tr>\n",
    "        <td colspan=\"5\" style=\"text-align: center;\"><h2><b>Portfolio - Deep Learning</b></h2></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Groepsnummer</th>\n",
    "        <th>Coach</th>\n",
    "        <th>Opdrachtnummer</th>\n",
    "        <th>Namen groepsleden</th>\n",
    "        <th>Kaggle naam</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><span style=\"color:blue\">2</span></td>\n",
    "        <td><span style=\"color:blue\">Vikram</span></td>\n",
    "        <td><span style=\"color:blue\">2</span></td>\n",
    "        <td>\n",
    "            <ul style=\"list-style-type:none; padding-left:0;\">\n",
    "                <li><b>Isa Dijkstra:</b> <span style=\"color:green\">22119485</span></li>\n",
    "                <li><b>Natasja de Kok:</b> <span style=\"color:green\">22059326</span></li>\n",
    "                <li><b>Vince Ammerlaan:</b> <span style=\"color:green\">21049599</span></li>\n",
    "            </ul>\n",
    "        </td>\n",
    "        <td><span style=\"color:blue\">1</span></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "    \n",
    "    \n",
    "## Inhoudsopgave\n",
    "\n",
    "- [**Inleiding**](#inleiding)\n",
    "- [**Packages en de data inladen**](#data)\n",
    "- [**Opdracht 1 - EDA**](#eda)\n",
    "- [**Opdracht 2 - Fully connected neuraal netwerk**](#CNN)\n",
    "- [**Opdracht 3 - Convolutioneel neuraal netwerk from scratch**](#CNNs)\n",
    "- [**Opdracht 4 - Transfer learning**](#tl)\n",
    "- [**Opdracht 5 - Multimodaal model**](#mm)\n",
    "- [**Opdracht 6 - Bevindingen**](#bevindingen)\n",
    "- [**Opdracht 7 - Conclusie en aanbevelingen**](#conclusie)\n",
    "- [**Bronnenlijst**](#bronnenlijst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages en de data inladen <a name='data'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import l1\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, BatchNormalization\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Input, concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Train.csv')\n",
    "test = pd.read_csv('Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train audio data shape: (537,)\n",
      "Train labels shape: 537\n",
      "Test audio data shape: (129,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mb/k89l7lfd07lb5zsng_4khpw80000gn/T/ipykernel_16182/2932808203.py:42: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  train_audio_data = np.array(train_audio_data)\n",
      "/var/folders/mb/k89l7lfd07lb5zsng_4khpw80000gn/T/ipykernel_16182/2932808203.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  test_audio_data = np.array(test_audio_data)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def load_data(data_dir):\n",
    "    audio_data = []\n",
    "    labels = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "        for filename in files:\n",
    "            if filename.endswith('.wav'):\n",
    "                filepath = os.path.join(root, filename)\n",
    "                try:\n",
    "                    y, sr = librosa.load(filepath, duration=30)  # Load only first 30 seconds\n",
    "                    audio_data.append(y)\n",
    "                    labels.append(os.path.basename(root))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {filepath}: {e}\")\n",
    "    \n",
    "    return audio_data, labels\n",
    "\n",
    "train_data_dir = \"Train\"\n",
    "test_data_dir = \"Test\"\n",
    "\n",
    "train_audio_data, train_labels = load_data(train_data_dir)\n",
    "test_audio_data, test_labels = load_data(test_data_dir)\n",
    "\n",
    "# Create label dictionaries for train and test sets\n",
    "train_label_dict = {label: index for index, label in enumerate(np.unique(train_labels))}\n",
    "test_label_dict = {label: index for index, label in enumerate(np.unique(test_labels))}\n",
    "\n",
    "# Convert train labels to numerical values using train_label_dict\n",
    "train_labels = [train_label_dict[label] for label in train_labels]\n",
    "\n",
    "# Convert test labels to numerical values using test_label_dict\n",
    "test_labels = [test_label_dict[label] for label in test_labels]\n",
    "\n",
    "# Convert audio data to numpy array\n",
    "train_audio_data = np.array(train_audio_data)\n",
    "test_audio_data = np.array(test_audio_data)\n",
    "\n",
    "# Check the shape of the arrays\n",
    "print(\"Train audio data shape:\", train_audio_data.shape)\n",
    "print(\"Train labels shape:\", len(train_labels))\n",
    "print(\"Test audio data shape:\", test_audio_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
